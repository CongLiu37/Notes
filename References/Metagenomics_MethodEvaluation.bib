@article{sczyrba2017critical,
  title={Critical assessment of metagenome interpretation—a benchmark of metagenomics software},
  author={Sczyrba, Alexander and Hofmann, Peter and Belmann, Peter and Koslicki, David and Janssen, Stefan and Dr{\"o}ge, Johannes and Gregor, Ivan and Majda, Stephan and Fiedler, Jessika and Dahms, Eik and others},
  journal={Nature methods},
  volume={14},
  number={11},
  pages={1063--1071},
  year={2017},
  publisher={Nature Publishing Group}
}
@article{becker2020modular,
  title={A Modular Metagenomics Pipeline Allowing for the Inclusion of Prior Knowledge Using the Example of Anaerobic Digestion},
  author={Becker, Daniela and Popp, Denny and Harms, Hauke and Centler, Florian},
  journal={Microorganisms},
  volume={8},
  number={5},
  pages={669},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
  abstract = {
    Metagenomics analysis revealing the composition and functional repertoire of complex microbial communities typically relies on large amounts of sequence data. Numerous analysis strategies and computational tools are available for their analysis. Fully integrated automated analysis pipelines such as MG-RAST or MEGAN6 are user-friendly but not designed for integrating specific knowledge on the biological system under study. In order to facilitate the consideration of such knowledge, we introduce a modular, adaptable analysis pipeline combining existing tools. We applied the novel pipeline to simulated mock data sets focusing on anaerobic digestion microbiomes and compare results to those obtained with established automated analysis pipelines. We find that the analysis strategy and choice of tools and parameters have a strong effect on the inferred taxonomic community composition, but not on the inferred functional profile. By including prior knowledge, computational costs can be decreased while improving result accuracy. While automated off-the-shelf analysis pipelines are easy to apply and require no knowledge on the microbial system under study, custom-made pipelines require more preparation time and bioinformatics expertise. This extra effort is minimized by our modular, flexible, custom-made pipeline, which can be adapted to different scenarios and can take available knowledge on the microbial system under study into account.
  }
}
@article{carr2014comparative,
  title={Comparative analysis of functional metagenomic annotation and the mappability of short reads},
  author={Carr, Rogan and Borenstein, Elhanan},
  journal={PloS one},
  volume={9},
  number={8},
  pages={e105776},
  year={2014},
  publisher={Public Library of Science San Francisco, USA}
  abstract = {
    To assess the functional capacities of microbial communities, including those inhabiting the human body, shotgun metagenomic reads are often aligned to a database of known genes. Such homology-based annotation practices critically rely on the assumption that short reads can map to orthologous genes of similar function. This assumption, however, and the various factors that impact short read annotation, have not been systematically evaluated. To address this challenge, we generated an extremely large database of simulated reads (totaling 15.9 Gb), spanning over 500,000 microbial genes and 170 curated genomes and including, for many genomes, every possible read of a given length. We annotated each read using common metagenomic protocols, fully characterizing the effect of read length, sequencing error, phylogeny, database coverage, and mapping parameters. We additionally rigorously quantified gene-, genome-, and protocol-specific annotation biases. Overall, our findings provide a first comprehensive evaluation of the capabilities and limitations of functional metagenomic annotation, providing crucial goal-specific best-practice guidelines to inform future metagenomic research.
  }
}
@article{wommack2008metagenomics,
  title={Metagenomics: read length matters},
  author={Wommack, K Eric and Bhavsar, Jaysheel and Ravel, Jacques},
  journal={Applied and environmental microbiology},
  volume={74},
  number={5},
  pages={1453--1463},
  year={2008},
  publisher={Am Soc Microbiol}
  abstract = {
    Obtaining an unbiased view of the phylogenetic composition and functional diversity within a microbial community is one central objective of metagenomic analysis. New technologies, such as 454 pyrosequencing, have dramatically reduced sequencing costs, to a level where metagenomic analysis may become a viable alternative to more-focused assessments of the phylogenetic (e.g., 16S rRNA genes) and functional diversity of microbial communities. To determine whether the short (∼100 to 200 bp) sequence reads obtained from pyrosequencing are appropriate for the phylogenetic and functional characterization of microbial communities, the results of BLAST and COG analyses were compared for long (∼750 bp) and randomly derived short reads from each of two microbial and one virioplankton metagenome libraries. Overall, BLASTX searches against the GenBank nr database found far fewer homologs within the short-sequence libraries. This was especially pronounced for a Chesapeake Bay virioplankton metagenome library. Increasing the short-read sampling depth or the length of derived short reads (up to 400 bp) did not completely resolve the discrepancy in BLASTX homolog detection. Only in cases where the long-read sequence had a close homolog (low BLAST E-score) did the derived short-read sequence also find a significant homolog. Thus, more-distant homologs of microbial and viral genes are not detected by short-read sequences. Among COG hits, derived short reads sampled at a depth of two short reads per long read missed up to 72% of the COG hits found using long reads. Noting the current limitation in computational approaches for the analysis of short sequences, the use of short-read-length libraries does not appear to be an appropriate tool for the metagenomic characterization of microbial communities.
  }
}
@article{sun2021challenges,
  title={Challenges in benchmarking metagenomic profilers},
  author={Sun, Zheng and Huang, Shi and Zhang, Meng and Zhu, Qiyun and Haiminen, Niina and Carrieri, Anna Paola and V{\'a}zquez-Baeza, Yoshiki and Parida, Laxmi and Kim, Ho-Cheol and Knight, Rob and others},
  journal={Nature methods},
  volume={18},
  number={6},
  pages={618--626},
  year={2021},
  publisher={Nature Publishing Group}
  abstract = {
    Accurate microbial identification and abundance estimation are crucial for metagenomics analysis. 
    Various methods for classification of metagenomic data and estimation of taxonomic profiles, broadly referred to as metagenomic profilers, have been developed. 
    Nevertheless, benchmarking of metagenomic profilers remains challenging because some tools are designed to report relative sequence abundance while others report relative taxonomic abundance. 
    Here we show how misleading conclusions can be drawn by neglecting this distinction between relative abundance types when benchmarking metagenomic profilers. 
    Moreover, we show compelling evidence that interchanging sequence abundance and taxonomic abundance will influence both per-sample summary statistics and cross-sample comparisons. 
    We suggest that the microbiome research community pay attention to potentially misleading biological conclusions arising from this issue when benchmarking metagenomic profilers, by carefully considering the type of abundance data that were analyzed and interpreted and clearly stating the strategy used for metagenomic profiling.
  }
}
@article{tran2020assembling,
  title={Assembling reads improves taxonomic classification of species},
  author={Tran, Quang and Phan, Vinhthuy},
  journal={Genes},
  volume={11},
  number={8},
  pages={946},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
  abstract = {
    Most current approach to metagenomic classification employ short next generation sequencing (NGS) reads that are present in metagenomic samples to identify unique genomic regions. NGS reads, however, might not be long enough to differentiate similar genomes. This suggests a potential for using longer reads to improve classification performance. Presently, longer reads tend to have a higher rate of sequencing errors. Thus, given the pros and cons, it remains unclear which types of reads is better for metagenomic classification. We compared two taxonomic classification protocols: a traditional assembly-free protocol and a novel assembly-based protocol. The novel assembly-based protocol consists of assembling short-reads into longer reads, which will be subsequently classified by a traditional taxonomic classifier. We discovered that most classifiers made fewer predictions with longer reads and that they achieved higher classification performance on synthetic metagenomic data. Generally, we observed a significant increase in precision, while having similar recall rates. On real data, we observed similar characteristics that suggest that the classifiers might have similar performance of higher precision with similar recall with longer reads. We have shown a noticeable difference in performance between assembly-based and assembly-free taxonomic classification. This finding strongly suggests that classifying species in metagenomic environments can be achieved with higher overall performance simply by assembling short reads. Further, it also suggests that long-read technologies might be better for species classification.
  }
}
@article{hallprofiling,
  title={Profiling Metagenomic Communities Using Circular Consensus and Single Molecule, Real-Time Sequencing},
  author={Hall, Richard J and Gale, Cheryl A and Hamilton, Matt and Heiseland, Tim and Knotted, Alex and Sadowsky, Michael and Silverstein, Kevin and Weingarden, Alexa and Heiner, Cheryl}
  abstract = {
    There are many sequencing-based approaches to understanding 
complex metagenomic communities, spanning targeted 
amplification to whole-sample shotgun sequencing. While 
targeted approaches provide valuable data at low sequencing 
depth, they are limited by primer design and PCR amplification. 
Whole-sample shotgun experiments require a high depth of 
coverage. As such, rare community members may not be 
represented in the resulting assembly. Circular-consensus, Single Molecule, Real-Time (SMRT®) 
Sequencing reads in the 1-2 kb range, with >99% consensus 
accuracy can be efficiently generated for low amounts of input 
DNA, e.g. as little as 10 ng of input DNA sequenced in 4 SMRT 
Cells can generate >100,000 such reads. While throughput is 
low compared to second-generation sequencing, the reads are a 
true random sampling of the underlying community. Long read 
lengths translate to a high number of the reads harboring full 
genes or even full operons for downstream analysis.  Here we present the results of circular-consensus sequencing on 
a mock  metagenomic community with an abundance range of 
multiple orders of magnitude, and compare the results with both 
16S and shotgun assembly methods. We show that even with 
relatively low sequencing depth, the long-read, assembly-free, 
random sampling allows to elucidate meaningful information 
from the very low-abundance community members. For 
example, given the above low-input sequencing approach, a 
community member at 1/1,000 relative abundance would 
generate 100 1-2 kb sequence fragments having 99% 
consensus accuracy, with a high probability of containing a gene 
fragment useful for taxonomic classification or functional insight. 
  }
}
@article{zhou2014assessment,
  title={Assessment of quality control approaches for metagenomic data analysis},
  author={Zhou, Qian and Su, Xiaoquan and Ning, Kang},
  journal={Scientific reports},
  volume={4},
  number={1},
  pages={1--11},
  year={2014},
  publisher={Nature Publishing Group}
  abstract = {
    Currently there is an explosive increase of the next-generation sequencing (NGS) projects and related datasets, which have to be processed by Quality Control (QC) procedures before they could be utilized for omics analysis. QC procedure usually includes identification and filtration of sequencing artifacts such as low-quality reads and contaminating reads, which would significantly affect and sometimes mislead downstream analysis. Quality control of NGS data for microbial communities is especially challenging. In this work, we have evaluated and compared the performance and effects of various QC pipelines on different types of metagenomic NGS data and from different angles, based on which general principles of using QC pipelines were proposed. Results based on both simulated and real metagenomic datasets have shown that: firstly, QC-Chain is superior in its ability for contamination identification for metagenomic NGS datasets with different complexities with high sensitivity and specificity. Secondly, the high performance computing engine enabled QC-Chain to achieve a significant reduction in processing time compared to other pipelines based on serial computing. Thirdly, QC-Chain could outperform other tools in benefiting downstream metagenomic data analysis.
  }
}
@article{tovo2020taxonomic,
  title={Taxonomic classification method for metagenomics based on core protein families with Core-Kaiju},
  author={Tovo, Anna and Menzel, Peter and Krogh, Anders and Cosentino Lagomarsino, Marco and Suweis, Samir},
  journal={Nucleic acids research},
  volume={48},
  number={16},
  pages={e93--e93},
  year={2020},
  publisher={Oxford University Press}
  abstract = {
    Characterizing species diversity and composition of bacteria hosted by biota is revolutionizing our understanding of the role of symbiotic interactions in ecosystems. Determining microbiomes diversity implies the assignment of individual reads to taxa by comparison to reference databases. Although computational methods aimed at identifying the microbe(s) taxa are available, it is well known that inferences using different methods can vary widely depending on various biases. In this study, we first apply and compare different bioinformatics methods based on 16S ribosomal RNA gene and shotgun sequencing to three mock communities of bacteria, of which the compositions are known. We show that none of these methods can infer both the true number of taxa and their abundances. We thus propose a novel approach, named Core-Kaiju, which combines the power of shotgun metagenomics data with a more focused marker gene classification method similar to 16S, but based on emergent statistics of core protein domain families. We thus test the proposed method on various mock communities and we show that Core-Kaiju reliably predicts both number of taxa and abundances. Finally, we apply our method on human gut samples, showing how Core-Kaiju may give more accurate ecological characterization and a fresh view on real microbiomes.
  }
}
@article{mende2012assessment,
  title={Assessment of metagenomic assembly using simulated next generation sequencing data},
  author={Mende, Daniel R and Waller, Alison S and Sunagawa, Shinichi and J{\"a}rvelin, Aino I and Chan, Michelle M and Arumugam, Manimozhiyan and Raes, Jeroen and Bork, Peer},
  journal={PloS one},
  volume={7},
  number={2},
  pages={e31386},
  year={2012},
  publisher={Public Library of Science San Francisco, USA}
  abstract = {
    Due to the complexity of the protocols and a limited knowledge of the nature of microbial communities, simulating metagenomic sequences plays an important role in testing the performance of existing tools and data analysis methods with metagenomic data. We developed metagenomic read simulators with platform-specific (Sanger, pyrosequencing, Illumina) base-error models, and simulated metagenomes of differing community complexities. We first evaluated the effect of rigorous quality control on Illumina data. Although quality filtering removed a large proportion of the data, it greatly improved the accuracy and contig lengths of resulting assemblies. We then compared the quality-trimmed Illumina assemblies to those from Sanger and pyrosequencing. For the simple community (10 genomes) all sequencing technologies assembled a similar amount and accurately represented the expected functional composition. For the more complex community (100 genomes) Illumina produced the best assemblies and more correctly resembled the expected functional composition. For the most complex community (400 genomes) there was very little assembly of reads from any sequencing technology. However, due to the longer read length the Sanger reads still represented the overall functional composition reasonably well. We further examined the effect of scaffolding of contigs using paired-end Illumina reads. It dramatically increased contig lengths of the simple community and yielded minor improvements to the more complex communities. Although the increase in contig length was accompanied by increased chimericity, it resulted in more complete genes and a better characterization of the functional repertoire. The metagenomic simulators developed for this research are freely available.
  }
}
@article{tamames2019assessing,
  title={Assessing the performance of different approaches for functional and taxonomic annotation of metagenomes},
  author={Tamames, Javier and Cobo-Sim{\'o}n, Marta and Puente-S{\'a}nchez, Fernando},
  journal={BMC genomics},
  volume={20},
  number={1},
  pages={1--16},
  year={2019},
  publisher={BioMed Central}
  abstract = {
    Background

Metagenomes can be analysed using different approaches and tools. One of the most important distinctions is the way to perform taxonomic and functional assignment, choosing between the use of assembly algorithms or the direct analysis of raw sequence reads instead by homology searching, k-mer analysys, or detection of marker genes. Many instances of each approach can be found in the literature, but to the best of our knowledge no evaluation of their different performances has been carried on, and we question if their results are comparable.
Results

We have analysed several real and mock metagenomes using different methodologies and tools, and compared the resulting taxonomic and functional profiles. Our results show that database completeness (the representation of diverse organisms and taxa in it) is the main factor determining the performance of the methods relying on direct read assignment either by homology, k-mer composition or similarity to marker genes, while methods relying on assembly and assignment of predicted genes are most influenced by metagenomic size, that in turn determines the completeness of the assembly (the percentage of read that were assembled).
Conclusions

Although differences exist, taxonomic profiles are rather similar between raw read assignment and assembly assignment methods, while they are more divergent for methods based on k-mers and marker genes. Regarding functional annotation, analysis of raw reads retrieves more functions, but it also makes a substantial number of over-predictions. Assembly methods are more advantageous as the size of the metagenome grows bigger.
  }
}